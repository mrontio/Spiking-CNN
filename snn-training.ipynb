{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e0d3330-3069-41b4-92b1-9da97132c4ca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tonic.datasets.nmnist import NMNIST\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "root_dir = './nmnist'\n",
    "_ = NMNIST(save_to=root_dir, train=True)\n",
    "_ = NMNIST(save_to=root_dir, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "221ac35f-805a-414c-9e69-ecc184c9c339",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tonic.transforms import ToFrame\n",
    "from tonic.datasets import nmnist\n",
    "\n",
    "batch_size = 1\n",
    "num_workers = 4\n",
    "device = \"cuda:0\"\n",
    "shuffle = True\n",
    "\n",
    "# Transform that accumulates events into single frame image\n",
    "to_frame = ToFrame(sensor_size=NMNIST.sensor_size, n_time_bins=1)\n",
    "\n",
    "train_dataset = NMNIST(save_to=root_dir, train=True, transform=to_frame)\n",
    "test_dataset = NMNIST(save_to=root_dir, train=False, transform=to_frame)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=shuffle)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "cc579952-7899-48c4-b5d6-ede02e0e1d69",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_linear = nn.Sequential(\n",
    "    # [2, 34, 34] -> [10]\n",
    "    nn.Linear(2 * 34 * 34, 10),\n",
    "    nn.ReLU(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d014191a-9f3a-4049-8d71-17317f8e3793",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_conv_linear = nn.Sequential(\n",
    "    # [2, 34, 34] -> [8, 17, 17]\n",
    "    nn.Conv2d(in_channels=2, out_channels=8, kernel_size=(3,3), padding=(1,1), bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(9248, 10, bias=False),\n",
    "    nn.ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ff798178-43e2-4185-b587-17c6ff6ec6aa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_conv_avg_linear = nn.Sequential(\n",
    "    # [2, 34, 34] -> [8, 17, 17]\n",
    "    nn.Conv2d(in_channels=2, out_channels=8, kernel_size=(3,3), padding=(1,1), bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(9248, 10, bias=False),\n",
    "    nn.ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "9ae85f35-53da-4212-beaa-59c5efbe013e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_sinabs = nn.Sequential(\n",
    "    # [2, 34, 34] -> [8, 17, 17]\n",
    "    nn.Conv2d(in_channels=2, out_channels=8, kernel_size=(3,3), padding=(1,1), bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2, 2),\n",
    "    \n",
    "    # [8, 17, 17] -> [16, 8, 8]\n",
    "    nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), padding=(1,1), bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2,2),\n",
    "    \n",
    "    # [16, 8, 8] -> [16, 4, 4]\n",
    "    nn.Conv2d(in_channels=16, out_channels=16, kernel_size = (3,3), padding=(1,1), stride=(2,2), bias=False),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    # [16 * 4 * 4] -> [10]\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 4 * 4, 10, bias=False),\n",
    "    nn.ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d0a8a583-3f24-4560-a8ab-ee7e4b54a3f3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:   0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:   2%|▏         | 932/60000 [00:01<01:03, 931.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:   3%|▎         | 2025/60000 [00:02<00:56, 1026.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:   5%|▌         | 3128/60000 [00:03<00:53, 1061.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:   7%|▋         | 4192/60000 [00:04<00:52, 1061.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:   9%|▉         | 5272/60000 [00:05<00:51, 1068.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  11%|█         | 6367/60000 [00:06<00:49, 1076.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  12%|█▏        | 7444/60000 [00:07<00:49, 1051.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  14%|█▍        | 8539/60000 [00:08<00:48, 1064.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  16%|█▌        | 9640/60000 [00:09<00:46, 1075.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  18%|█▊        | 10723/60000 [00:10<00:45, 1077.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  20%|█▉        | 11807/60000 [00:11<00:44, 1079.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  21%|██▏       | 12887/60000 [00:12<00:43, 1077.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  23%|██▎       | 13980/60000 [00:13<00:42, 1081.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  25%|██▌       | 15063/60000 [00:14<00:41, 1077.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  27%|██▋       | 16191/60000 [00:15<00:40, 1092.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  29%|██▉       | 17286/60000 [00:16<00:39, 1093.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  31%|███       | 18393/60000 [00:17<00:37, 1097.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  32%|███▏      | 19491/60000 [00:18<00:36, 1095.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  34%|███▍      | 20619/60000 [00:19<00:35, 1105.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  36%|███▌      | 21725/60000 [00:20<00:35, 1089.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  38%|███▊      | 22820/60000 [00:21<00:34, 1091.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  40%|███▉      | 23912/60000 [00:22<00:33, 1090.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  42%|████▏     | 25021/60000 [00:23<00:31, 1095.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  44%|████▎     | 26122/60000 [00:24<00:30, 1097.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  45%|████▌     | 27220/60000 [00:25<00:30, 1087.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  47%|████▋     | 28367/60000 [00:26<00:28, 1105.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  49%|████▉     | 29500/60000 [00:27<00:27, 1113.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  51%|█████     | 30614/60000 [00:28<00:26, 1101.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  53%|█████▎    | 31744/60000 [00:29<00:25, 1109.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  55%|█████▍    | 32866/60000 [00:30<00:24, 1113.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  57%|█████▋    | 33980/60000 [00:31<00:23, 1092.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  59%|█████▊    | 35122/60000 [00:32<00:22, 1106.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  60%|██████    | 36272/60000 [00:33<00:21, 1119.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  62%|██████▏   | 37393/60000 [00:34<00:20, 1102.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  64%|██████▍   | 38497/60000 [00:35<00:19, 1100.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  66%|██████▌   | 39599/60000 [00:36<00:18, 1096.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  68%|██████▊   | 40722/60000 [00:37<00:17, 1104.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  70%|██████▉   | 41827/60000 [00:38<00:16, 1100.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  72%|███████▏  | 42929/60000 [00:39<00:15, 1093.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  73%|███████▎  | 44024/60000 [00:40<00:14, 1091.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  75%|███████▌  | 45116/60000 [00:41<00:13, 1085.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  77%|███████▋  | 46202/60000 [00:42<00:12, 1067.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  79%|███████▉  | 47270/60000 [00:43<00:12, 1054.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  81%|████████  | 48325/60000 [00:44<00:11, 1031.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  82%|████████▏ | 49358/60000 [00:45<00:10, 1028.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  84%|████████▍ | 50387/60000 [00:46<00:09, 1024.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  86%|████████▌ | 51423/60000 [00:47<00:08, 1027.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  87%|████████▋ | 52475/60000 [00:48<00:07, 1034.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  89%|████████▉ | 53546/60000 [00:49<00:06, 1045.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  91%|█████████ | 54592/60000 [00:50<00:05, 1035.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  93%|█████████▎| 55655/60000 [00:51<00:04, 1043.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  95%|█████████▍| 56728/60000 [00:52<00:03, 1052.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  96%|█████████▋| 57781/60000 [00:53<00:02, 1038.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3:  98%|█████████▊| 58820/60000 [00:54<00:01, 1027.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/3: 100%|█████████▉| 59849/60000 [00:55<00:00, 1024.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 0, testing model.:   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 0, testing model.:  14%|█▍        | 1443/10000 [00:01<00:05, 1442.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 0, testing model.:  31%|███       | 3123/10000 [00:02<00:04, 1581.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 0, testing model.:  48%|████▊     | 4833/10000 [00:03<00:03, 1640.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 0, testing model.:  66%|██████▌   | 6620/10000 [00:04<00:01, 1697.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 0, testing model.:  84%|████████▎ | 8355/10000 [00:05<00:00, 1711.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 0, testing model.: 100%|██████████| 10000/10000 [00:05<00:00, 1686.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 - accuracy: 89.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:   0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:   2%|▏         | 942/60000 [00:01<01:02, 941.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:   3%|▎         | 2044/60000 [00:02<00:55, 1035.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:   5%|▌         | 3080/60000 [00:03<00:55, 1031.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:   7%|▋         | 4118/60000 [00:04<00:54, 1034.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:   9%|▊         | 5218/60000 [00:05<00:51, 1057.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  10%|█         | 6280/60000 [00:06<00:50, 1059.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  12%|█▏        | 7349/60000 [00:07<00:49, 1062.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  14%|█▍        | 8421/60000 [00:08<00:48, 1065.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  16%|█▌        | 9515/60000 [00:09<00:47, 1073.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  18%|█▊        | 10589/60000 [00:10<00:46, 1072.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  19%|█▉        | 11673/60000 [00:11<00:44, 1075.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  21%|██        | 12749/60000 [00:12<00:44, 1065.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  23%|██▎       | 13830/60000 [00:13<00:43, 1069.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  25%|██▍       | 14900/60000 [00:14<00:42, 1062.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  27%|██▋       | 16029/60000 [00:15<00:40, 1082.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  29%|██▊       | 17112/60000 [00:16<00:40, 1071.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  30%|███       | 18184/60000 [00:17<00:39, 1049.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  32%|███▏      | 19257/60000 [00:18<00:38, 1056.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  34%|███▍      | 20338/60000 [00:19<00:37, 1063.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  36%|███▌      | 21422/60000 [00:20<00:36, 1069.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  38%|███▊      | 22547/60000 [00:21<00:34, 1085.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  39%|███▉      | 23634/60000 [00:22<00:34, 1052.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  41%|████      | 24690/60000 [00:23<00:33, 1053.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  43%|████▎     | 25746/60000 [00:24<00:32, 1053.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  45%|████▍     | 26802/60000 [00:25<00:31, 1053.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  47%|████▋     | 27936/60000 [00:26<00:29, 1077.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  48%|████▊     | 29068/60000 [00:27<00:28, 1093.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  50%|█████     | 30193/60000 [00:28<00:27, 1102.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  52%|█████▏    | 31297/60000 [00:29<00:26, 1091.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  54%|█████▍    | 32390/60000 [00:30<00:25, 1091.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  56%|█████▌    | 33482/60000 [00:31<00:24, 1071.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  58%|█████▊    | 34581/60000 [00:32<00:23, 1079.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  59%|█████▉    | 35682/60000 [00:33<00:22, 1085.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  61%|██████▏   | 36793/60000 [00:34<00:21, 1093.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  63%|██████▎   | 37915/60000 [00:35<00:20, 1101.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  65%|██████▌   | 39017/60000 [00:36<00:19, 1082.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  67%|██████▋   | 40101/60000 [00:37<00:18, 1069.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  69%|██████▊   | 41225/60000 [00:38<00:17, 1085.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  71%|███████   | 42350/60000 [00:39<00:16, 1096.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  72%|███████▏  | 43448/60000 [00:40<00:15, 1088.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  74%|███████▍  | 44538/60000 [00:41<00:14, 1072.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  76%|███████▌  | 45612/60000 [00:42<00:13, 1047.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  78%|███████▊  | 46744/60000 [00:43<00:12, 1071.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  80%|███████▉  | 47818/60000 [00:44<00:11, 1063.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  81%|████████▏ | 48895/60000 [00:45<00:10, 1067.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  83%|████████▎ | 50031/60000 [00:46<00:09, 1087.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  85%|████████▌ | 51120/60000 [00:47<00:08, 1064.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  87%|████████▋ | 52187/60000 [00:48<00:07, 1049.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  89%|████████▊ | 53238/60000 [00:49<00:06, 1044.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  91%|█████████ | 54318/60000 [00:50<00:05, 1054.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  92%|█████████▏| 55374/60000 [00:51<00:04, 1051.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  94%|█████████▍| 56426/60000 [00:52<00:03, 1036.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  96%|█████████▌| 57503/60000 [00:53<00:02, 1048.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  98%|█████████▊| 58553/60000 [00:54<00:01, 1040.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/3:  99%|█████████▉| 59640/60000 [00:55<00:00, 1054.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1, testing model.:   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1, testing model.:  15%|█▍        | 1477/10000 [00:01<00:05, 1476.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1, testing model.:  32%|███▏      | 3240/10000 [00:02<00:04, 1644.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1, testing model.:  50%|████▉     | 4975/10000 [00:03<00:02, 1685.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1, testing model.:  67%|██████▋   | 6731/10000 [00:04<00:01, 1713.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1, testing model.:  85%|████████▌ | 8547/10000 [00:05<00:00, 1749.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1, testing model.: 100%|██████████| 10000/10000 [00:05<00:00, 1712.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 - accuracy: 94.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:   0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:   1%|▏         | 856/60000 [00:01<01:09, 855.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:   3%|▎         | 1972/60000 [00:02<00:57, 1008.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:   5%|▌         | 3052/60000 [00:03<00:54, 1040.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:   7%|▋         | 4093/60000 [00:04<00:53, 1037.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:   9%|▊         | 5215/60000 [00:05<00:51, 1067.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  10%|█         | 6283/60000 [00:06<00:51, 1052.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  12%|█▏        | 7337/60000 [00:07<00:50, 1043.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  14%|█▍        | 8389/60000 [00:08<00:49, 1045.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  16%|█▌        | 9457/60000 [00:09<00:48, 1052.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  18%|█▊        | 10528/60000 [00:10<00:46, 1058.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  19%|█▉        | 11587/60000 [00:11<00:45, 1057.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  21%|██        | 12657/60000 [00:12<00:44, 1061.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  23%|██▎       | 13719/60000 [00:13<00:43, 1053.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  25%|██▍       | 14813/60000 [00:14<00:42, 1065.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  26%|██▋       | 15879/60000 [00:15<00:41, 1061.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  28%|██▊       | 16942/60000 [00:16<00:41, 1042.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  30%|███       | 18077/60000 [00:17<00:39, 1069.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  32%|███▏      | 19148/60000 [00:18<00:38, 1068.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  34%|███▍      | 20300/60000 [00:19<00:36, 1093.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  36%|███▌      | 21394/60000 [00:20<00:35, 1078.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  37%|███▋      | 22496/60000 [00:21<00:34, 1085.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  39%|███▉      | 23583/60000 [00:22<00:33, 1083.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  41%|████      | 24667/60000 [00:23<00:33, 1066.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  43%|████▎     | 25735/60000 [00:24<00:32, 1056.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  45%|████▍     | 26793/60000 [00:25<00:31, 1046.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  47%|████▋     | 27912/60000 [00:26<00:30, 1067.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  48%|████▊     | 28981/60000 [00:27<00:29, 1059.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  50%|█████     | 30101/60000 [00:28<00:27, 1077.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  52%|█████▏    | 31179/60000 [00:29<00:26, 1072.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  54%|█████▍    | 32262/60000 [00:30<00:25, 1075.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  56%|█████▌    | 33355/60000 [00:31<00:24, 1080.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  57%|█████▋    | 34453/60000 [00:32<00:23, 1085.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  59%|█████▉    | 35563/60000 [00:33<00:22, 1092.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  61%|██████    | 36656/60000 [00:34<00:21, 1082.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  63%|██████▎   | 37739/60000 [00:35<00:20, 1079.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  65%|██████▍   | 38837/60000 [00:36<00:19, 1084.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  67%|██████▋   | 39923/60000 [00:37<00:18, 1075.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  68%|██████▊   | 40999/60000 [00:38<00:17, 1059.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  70%|███████   | 42067/60000 [00:39<00:16, 1061.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  72%|███████▏  | 43130/60000 [00:40<00:16, 1050.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  74%|███████▎  | 44231/60000 [00:41<00:14, 1065.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  76%|███████▌  | 45320/60000 [00:42<00:13, 1072.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  77%|███████▋  | 46393/60000 [00:43<00:12, 1067.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  79%|███████▉  | 47505/60000 [00:44<00:11, 1080.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  81%|████████  | 48586/60000 [00:45<00:10, 1079.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  83%|████████▎ | 49737/60000 [00:46<00:09, 1100.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  85%|████████▍ | 50858/60000 [00:47<00:08, 1106.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  87%|████████▋ | 51965/60000 [00:48<00:07, 1094.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  88%|████████▊ | 53081/60000 [00:49<00:06, 1100.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  90%|█████████ | 54182/60000 [00:50<00:05, 1095.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  92%|█████████▏| 55279/60000 [00:51<00:04, 1087.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  94%|█████████▍| 56368/60000 [00:52<00:03, 1081.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  96%|█████████▌| 57451/60000 [00:53<00:02, 1079.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  98%|█████████▊| 58532/60000 [00:54<00:01, 1069.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/3:  99%|█████████▉| 59602/60000 [00:55<00:00, 1064.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2, testing model.:   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2, testing model.:  15%|█▌        | 1544/10000 [00:01<00:05, 1543.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2, testing model.:  33%|███▎      | 3262/10000 [00:02<00:04, 1645.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2, testing model.:  50%|█████     | 5009/10000 [00:03<00:02, 1691.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2, testing model.:  68%|██████▊   | 6765/10000 [00:04<00:01, 1717.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2, testing model.:  85%|████████▌ | 8512/10000 [00:05<00:00, 1727.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2, testing model.: 100%|██████████| 10000/10000 [00:06<00:00, 1662.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 - accuracy: 94.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = model_sinabs\n",
    "\n",
    "epochs = 3\n",
    "lr = 1e-3\n",
    "\n",
    "# init the model weights\n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.xavier_normal_(layer.weight.data)\n",
    "\n",
    "optimizer = SGD(params=model.parameters(), lr=lr)\n",
    "criterion = CrossEntropyLoss()\n",
    "model.to(device)\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    # train\n",
    "    train_p_bar = tqdm(train_dataloader, desc=f'Epoch {e+1}/{epochs}', leave=False, mininterval=1)\n",
    "    for data, label in train_p_bar:\n",
    "        # remove the time-step axis since we are training model\n",
    "        # move the data to accelerator\n",
    "        data = data.squeeze(dim=1).to(dtype=torch.float, device=device)\n",
    "        label = label.to(dtype=torch.long, device=device)\n",
    "        # forward\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # set progressing bar\n",
    "        #train_p_bar.set_postfix(loss=round(loss.item(), 4), mininterval=1)\n",
    "\n",
    "    # validate\n",
    "    correct_predictions = []\n",
    "    with torch.no_grad():\n",
    "        test_p_bar = tqdm(test_dataloader, desc=f'Epoch {e}, testing model.', mininterval=1)\n",
    "        for data, label in test_p_bar:\n",
    "            # remove the time-step axis since we are training model\n",
    "            # move the data to accelerator\n",
    "            data = data.squeeze(dim=1).to(dtype=torch.float, device=device)\n",
    "            label = label.to(dtype=torch.long, device=device)\n",
    "            # forward\n",
    "            output = model(data)\n",
    "            # calculate accuracy\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            # compute the total correct predictions\n",
    "            correct_predictions.append(pred.eq(label.view_as(pred)))\n",
    "    \n",
    "        correct_predictions = torch.cat(correct_predictions)\n",
    "        print(f\"\\nEpoch {e} - accuracy: {correct_predictions.sum().item()/(len(correct_predictions))*100}%\")\n",
    "torch.save(model.state_dict(), \"./weights/model-weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c54bbcdc-203e-4b93-9e5f-baee4996c409",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2202997/3734851863.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"./weights/model-weights.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_sinabs\n",
    "model.load_state_dict(torch.load(\"./weights/model-weights.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456ea942-e016-421d-bd93-b08d76385aee",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (1): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "  tensor(1.), min_v_mem=Parameter containing:\n",
       "  tensor(-1.), batch_size=1, num_timesteps=-1)\n",
       "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (4): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "  tensor(1.), min_v_mem=Parameter containing:\n",
       "  tensor(-1.), batch_size=1, num_timesteps=-1)\n",
       "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (7): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "  tensor(1.), min_v_mem=Parameter containing:\n",
       "  tensor(-1.), batch_size=1, num_timesteps=-1)\n",
       "  (8): Flatten(start_dim=1, end_dim=-1)\n",
       "  (9): Linear(in_features=256, out_features=10, bias=False)\n",
       "  (10): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "  tensor(1.), min_v_mem=Parameter containing:\n",
       "  tensor(-1.), batch_size=1, num_timesteps=-1)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sinabs.from_torch import from_model\n",
    "import sinabs.activation.spike_generation as spikegen\n",
    "\n",
    "snn = from_model(model=model, input_shape=(2, 34, 34), batch_size=1, spike_fn=spikegen.SingleSpike).spiking_model\n",
    "snn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c2a3db6c-87c5-4635-aed1-8c214b73adc7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "n_time_steps = 100\n",
    "to_raster = ToFrame(sensor_size=NMNIST.sensor_size, n_time_bins=n_time_steps)\n",
    "snn_test_dataset = NMNIST(save_to=root_dir, train=False, transform=to_raster)\n",
    "snn_test_dataloader = DataLoader(snn_test_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=False)\n",
    "\n",
    "snn = snn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "05bd7ac5-20ee-47f0-bb40-0b53394a8ec4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Testing model.:   0%|          | 0/2500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Testing model.:   0%|          | 0/2500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[239], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43msnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# reshape the output from [Batch*Time,num_classes] into [Batch, Time, num_classes]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mreshape(batch_size, n_time_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/ml-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ml-venv/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/ml-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ml-venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml-venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "correct_predictions = []\n",
    "with torch.no_grad():\n",
    "    test_p_bar = tqdm(snn_test_dataloader,  desc=f'Testing model.', mininterval=1)\n",
    "    for data, label in test_p_bar:\n",
    "        # reshape the input from [Batch, Time, Channel, Height, Width] into [Batch*Time, Channel, Height, Width]\n",
    "        data = data.reshape(-1, 2, 34, 34).to(dtype=torch.float, device=device)\n",
    "        label = label.to(dtype=torch.long, device=device)\n",
    "        # forward\n",
    "        output = snn(data)\n",
    "        # reshape the output from [Batch*Time,num_classes] into [Batch, Time, num_classes]\n",
    "        output = output.reshape(batch_size, n_time_steps, -1)\n",
    "        # accumulate all time-steps output for final prediction\n",
    "        output = output.sum(dim=1)\n",
    "        # calculate accuracy\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        # compute the total correct predictions\n",
    "        correct_predictions.append(pred.eq(label.view_as(pred)))\n",
    "        # set progressing bar\n",
    "        test_p_bar.update()\n",
    "        #test_p_bar.set_description(f\"Testing SNN Model...\")\n",
    "\n",
    "    correct_predictions = torch.cat(correct_predictions)\n",
    "    print(f\"\\nAccuracy of converted SNN: {correct_predictions.sum().item()/(len(correct_predictions))*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "750496e6-b196-4839-98fe-8cb79639fe1b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dataloader_to_numpy(dataloader):\n",
    "    count = 0\n",
    "    for batch in dataloader:\n",
    "        for i in range(batch[0].shape[0]):\n",
    "            x = batch[0][i]\n",
    "            y = batch[1][i]\n",
    "            saved_x = x.to(device=\"cpu\", dtype=torch.float).detach().numpy()\n",
    "            np.save(f'/home/mrontio/data/nmnist-converted/{y}/{count}.npy', saved_x)\n",
    "            count += 1\n",
    "\n",
    "dataloader_to_numpy(snn_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a619e2-24ca-4731-8919-b9fbefcfa2e5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2, 34, 34)\n",
      "tensor([[0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sample_data, label = snn_test_dataset[0]\n",
    "print(sample_data.shape)\n",
    "sample_data = torch.tensor(sample_data).reshape(-1, 2, 34, 34).to(dtype=torch.float, device=device)\n",
    "logits = snn(sample_data).reshape(1, 100, -1)\n",
    "output = logits.sum(dim=1)\n",
    "pred = output.argmax(dim=1, keepdim=True)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44e1b1c9-e372-46e2-b2a9-890c08072ece",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = snn.to('cpu')\n",
    "zeros = torch.zeros(sample_data.shape)\n",
    "ones = torch.ones(sample_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "016078e2-2f23-4ce7-b971-c78a220a97e6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spike_threshold: 1.0\n",
      "min_v_mem: -1.0\n"
     ]
    }
   ],
   "source": [
    "modules = list(snn.modules())[1:]\n",
    "print(f'spike_threshold: {float(modules[1].spike_threshold)}\\nmin_v_mem: {float(modules[1].min_v_mem)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86ab4e7e-674c-4809-af0c-8101e836b9cd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.3294, grad_fn=<MinBackward1>) tensor(3.9885, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "conv = modules[0]\n",
    "conv_out = conv(ones)\n",
    "iaf = modules[1]\n",
    "iaf_out = iaf(conv_out)\n",
    "\n",
    "print(torch.min(conv_out), torch.max(conv_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0897f249-32d9-42bd-ae69-c4c8744d39d2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 8, 34, 34])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = list(conv.parameters())[0]\n",
    "W.shape\n",
    "conv_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c99dc87b-edb8-461f-a8f3-39650356d4ee",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_tensor(tensor, ax, printcb=False):\n",
    "    if tensor.dim() != 2:\n",
    "        raise ValueError(\"Input tensor must be a 2D tensor.\")\n",
    "    \n",
    "    tensor_np = tensor.numpy()  # Convert to numpy array\n",
    "    ax.imshow(tensor_np, cmap='coolwarm', aspect='equal')\n",
    "\n",
    "    cax = ax.imshow(tensor_np, cmap='coolwarm', aspect='equal')\n",
    "    if printcb:\n",
    "        fig.colorbar(cax, ax=ax)  # Show color scale\n",
    "    ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71660d91-3d7b-4553-9a14-7b4d2eb4bad9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_class_name(class_string):\n",
    "    # Strip the angle brackets and split the string by dots\n",
    "    split_string = class_string.strip(\"<>\").split(\".\")\n",
    "    # Get the last element from the split string\n",
    "    class_name = split_string[-1]\n",
    "    # Remove the ending single quote if it exists\n",
    "    return class_name.strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab1508ea-50bb-4c23-ba2a-6c32643553a2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 30, 100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x700 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sinabs.layers import IAF,LIF\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#tensor = torch.rand((1, 2, 34, 34))\n",
    "#tensor[0,1] = tensor[0,0]\n",
    "begin = 0\n",
    "end = 3\n",
    "tensor = torch.linspace(begin, end, steps=100).repeat(30, 1)\n",
    "iaf = IAF(spike_fn = spikegen.SingleSpike, record_states=True)\n",
    "\n",
    "t = 5\n",
    "\n",
    "image = tensor.unsqueeze(0)\n",
    "image = torch.stack([image] * t, dim=1)\n",
    "\n",
    "title = f'Linspace [{begin},{end}], {get_class_name(str(iaf.spike_fn))}'\n",
    "\n",
    "# image[0, 1:3] = torch.zeros((30, 100))\n",
    "# image[0, 3] = torch.zeros((30, 100))\n",
    "# title += ', with interruptions'\n",
    "#image = sample_data[10].unsqueeze(0).cpu()\n",
    "print(image.shape)\n",
    "fig, ax = plt.subplots(image.shape[1], 2, figsize=(5,7))\n",
    "for i in range(image.shape[1]):\n",
    "    with torch.no_grad():\n",
    "        plot_tensor(image[0,i], ax[i,0])\n",
    "        plot_tensor(iaf(image)[0,i], ax[i, 1])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.suptitle(title)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72128438-19ef-40fc-86e5-d46ea79d3ca0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 30, 100])\n",
      "tensor(0.9091)\n",
      "0.9091 -> 0.0909\n",
      "0.9091 -> 0.0000\n",
      "0.9091 -> 0.9091\n",
      "0.9091 -> 0.8182\n",
      "0.9091 -> 0.7273\n"
     ]
    }
   ],
   "source": [
    "recordings = iaf.recordings['v_mem']\n",
    "x = 30\n",
    "y = 0\n",
    "print(recordings.shape)\n",
    "print(image[0, 0, y, x])\n",
    "for i in range(recordings.shape[1]):\n",
    "    print(f'{float(image[0,i,y,x]):.4f} -> {float(recordings[0,i,y,x]):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32df026e-0bca-41f4-9b81-410c55fde028",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def conv_layer(x: 'np.ndarray[np.float32]', W):\n",
    "    C_in = W.shape[1]\n",
    "    C_out = W.shape[0]\n",
    "    kernel_size = tuple((W.shape[2:4]))\n",
    "    timesteps = x.shape[0]\n",
    "    stride = 1\n",
    "    padding = (1,1)\n",
    "    # Zero pad\n",
    "    data_padded = torch.zeros(x.shape[0],\n",
    "                              x.shape[1] + 2*padding[0],\n",
    "                              x.shape[2] + 2*padding[0])\n",
    "    data_padded[:, padding[0]:x.shape[1] + padding[0], padding[1]:x.shape[2] + padding[1]] = x.cpu()\n",
    "    output = torch.zeros(C_out, x.shape[1], x.shape[2])\n",
    "    \n",
    "    coordinate_pairs = [(a, b) for a in range(0, x.shape[1], stride) for b in range(0, x.shape[2], stride)]\n",
    "    for l in range(C_out):\n",
    "        for k in range(C_in):\n",
    "            kernel = W[l,k]\n",
    "            for i, j in coordinate_pairs:\n",
    "                i_pad = i + padding[0]\n",
    "                j_pad = j + padding[1]\n",
    "                for m_ in range(kernel_size[0]):\n",
    "                    m = m_ - 1\n",
    "                    for n_ in range(kernel_size[1]):\n",
    "                        n = n_ -1\n",
    "                        output[l, i, j] += (kernel[m_, n_]\n",
    "                                            * data_padded[k, i_pad + m, j_pad + n])\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "x = torch.ones([2, 34, 34])\n",
    "# sample_data.to('cpu')\n",
    "# x = sample_data[0].to('cpu')\n",
    "conv_theirs = conv(x)\n",
    "conv_mine = conv_layer(x, W)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6902c5a-449e-482f-9e1a-39f78d4bf83b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 9248, False: 0\n",
      "tensor(-0.5376, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5376, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "precision = 5\n",
    "mine_round = torch.round(conv_mine * 10**precision) / 10**precision\n",
    "theirs_round = torch.round(conv_theirs * 10**precision) / 10**precision\n",
    "num_true = torch.sum(mine_round == theirs_round).item()\n",
    "num_false = (mine_round==theirs_round).numel() - num_true\n",
    "print(f'True: {num_true}, False: {num_false}')\n",
    "false_indexes = torch.nonzero((conv_mine == conv_theirs) == False, as_tuple=False)\n",
    "print(conv_theirs[0,0,0])\n",
    "print(conv_mine[0,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b54109d7-ab59-4bd7-a323-77a4fb4573af",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "weights_np = W.detach().numpy() \n",
    "theirs_np = conv_theirs.detach().numpy()\n",
    "mine_np = conv_mine.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1f1c0c8-e136-42dd-8cdc-fe236c2a4f5c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 34, 34])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_mine.reshape(1, 1, 8, 34, 34).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd00d71a-e630-47f4-a54c-3a2ea9837c86",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class if_layer:\n",
    "    def __init__(self, input_shape):\n",
    "        self.membrane = torch.zeros(input_shape)\n",
    "        self.coordinate_pairs = [(a, b) for a in range(input_shape[1]) for b in range(input_shape[2])]\n",
    "        self.v_th = 1.0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.membrane = torch.zeros(input_shape)\n",
    "    def __call__(self, x: 'np.ndarray[np.float32]'):\n",
    "        '''Basic implementation of IF layer.\n",
    "        Assumptions:\n",
    "        spike_threshold = 1.0,\n",
    "        spike_fn = SingleSpike\n",
    "        No batch, No timing: the FPGA simply runs everything on FIFO basis\n",
    "        Thererofe, this has to be a class.\n",
    "        x dimensions: [c, y, x]\n",
    "        '''\n",
    "        output = torch.zeros(self.membrane.shape)\n",
    "        for c in range(x.shape[0]):\n",
    "            for (i, j) in self.coordinate_pairs:\n",
    "                self.membrane[c, i, j] +=  x[c, i, j]\n",
    "\n",
    "                if self.membrane[c, i, j] > self.v_th:\n",
    "                    output[c,i,j] = 1;\n",
    "                    self.membrane[c, i, j] -= 1\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "ac4dea49-520a-40c5-9f96-853d3d4f1708",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class if1_layer:\n",
    "    \"\"\"Expect input shape: [time, channel, y, x]\"\"\"\n",
    "    def __init__(self, input_shape, rec=None):\n",
    "        self.timesteps = input_shape[0]\n",
    "        self.elems = torch.tensor(input_shape[1:]).prod().item()\n",
    "        self.membrane = torch.zeros([self.elems])\n",
    "        if rec != None:\n",
    "            self.recs = list()\n",
    "            self.reci = torch.tensor(rec).prod().item()\n",
    "        else:\n",
    "            self.recs = None\n",
    "        self.v_th = 1.0\n",
    "\n",
    "    def reset(self):\n",
    "        self.membrane = torch.zeros(input_shape)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        input_shape = x.shape\n",
    "        x = x.reshape((self.timesteps, self.elems))\n",
    "        output = torch.zeros((self.timesteps, self.elems))\n",
    "        recs = list()\n",
    "        for t in range(self.timesteps):\n",
    "            for e in range(self.elems):\n",
    "                self.membrane[e] +=  x[t, e]\n",
    "                if self.membrane[e] >= self.v_th:\n",
    "                    output[t, e] = 1;\n",
    "                    self.membrane[e] -= 1\n",
    "\n",
    "                if self.membrane[e] < -1:\n",
    "                    self.membrane[e] = -1\n",
    "            if self.recs != None:\n",
    "                self.recs.append(self.membrane[self.reci].item())\n",
    "\n",
    "        output = output.reshape(input_shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "c559f7c9-22e7-4942-90c0-271c367cd88c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 8, 34, 34]) torch.Size([1, 100, 8, 34, 34])\n"
     ]
    }
   ],
   "source": [
    "data_me = torch.ones((100, 8, 34, 34)) * 0.2\n",
    "data_them = data_me.unsqueeze(0)\n",
    "print(data_me.shape, data_them.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9755aa0-28fd-4865-adb0-8f06de2fd8dd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def avg_pool2d(x):\n",
    "    kernel = (2,2)\n",
    "    stride = 2\n",
    "    padding = 0\n",
    "\n",
    "    # Create output buffer\n",
    "    H_out = math.floor((x.shape[1] + (2 * padding) - kernel[0]) / stride) + 1\n",
    "    W_out = math.floor((x.shape[2] + (2 * padding) - kernel[0]) / stride) + 1\n",
    "    output = torch.zeros((x.shape[0], H_out, W_out))\n",
    "\n",
    "    # Zero pad\n",
    "    data_padded = torch.zeros(x.shape[0],\n",
    "                              x.shape[1] + 2*padding,\n",
    "                              x.shape[2] + 2*padding)\n",
    "    data_padded[:, padding:x.shape[1] + padding, padding:x.shape[2] + padding] = x.cpu()\n",
    "\n",
    "    coordinate_pairs = [(a, b) for a in range(H_out) for b in range(W_out)]\n",
    "    coordinate_pairs.sort()\n",
    "    kernel_pairs = [(a, b) for a in range(kernel[0]) for b in range(kernel[1])]\n",
    "    kernel_pairs.sort()\n",
    "    for c in range(output.shape[0]):\n",
    "        for (h, w) in coordinate_pairs:\n",
    "            # Apply kernel\n",
    "            kernel_sum = 0\n",
    "            for (m, n) in kernel_pairs:\n",
    "                kernel_sum += data_padded[c, stride * h + m, stride * w + n]\n",
    "            output[c, h, w] = 1 / (kernel[0] * kernel[1]) * kernel_sum\n",
    "\n",
    "    return output                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bd8014a-d5f5-4ee7-af91-5eee35ab59d3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_module_name(input_string):\n",
    "    input_string = str(input_string)\n",
    "    # Pattern to match the function name and contents within first\n",
    "    pattern = r\"^([a-zA-Z_][a-zA-Z0-9_]*)\\(.*\"\n",
    "    \n",
    "    match = re.match(pattern, input_string)\n",
    "    if match:\n",
    "        return match.group(1)  # Return the function name\n",
    "    else:\n",
    "        return None  # If there's no match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dcf2a2-b523-483f-8d52-7de76dfeca69",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Weight Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "97fe058b-dcee-45ad-a642-1ecfacc39ea5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weights ./weights/0-Conv2d.npy : torch.Size([8, 2, 3, 3])\n",
      "Saved weights ./weights/3-Conv2d.npy : torch.Size([16, 8, 3, 3])\n",
      "Saved weights ./weights/6-Conv2d.npy : torch.Size([16, 16, 3, 3])\n",
      "Saved weights ./weights/9-Linear.npy : torch.Size([10, 256])\n",
      "\n",
      "[2024-09-09T16:41:54.145230] Saved weights\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import datetime \n",
    "snn = from_model(model=model, input_shape=(2, 34, 34), batch_size=1, spike_fn=spikegen.SingleSpike).spiking_model.to('cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (i, m) in enumerate(list(snn.modules())[1:]):\n",
    "        mod_name = get_module_name(m)\n",
    "\n",
    "        if mod_name == 'Conv2d' or mod_name == 'Linear':\n",
    "            save_name = f'./weights/{i}-{mod_name}.npy'\n",
    "            np.save(save_name, list(m.parameters())[0])\n",
    "            print(f'Saved weights {save_name} : {list(m.parameters())[0].shape}')\n",
    "\n",
    "        if mod_name == 'Flatten':\n",
    "            m = nn.Flatten(start_dim=0)\n",
    "\n",
    "print(f'\\n[{datetime.datetime.now().isoformat()}] Saved weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "b50a6427-cf04-40fc-a744-85210b63d611",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: torch.Size([100, 2, 34, 34])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test completed successfully.\n",
      "Prediction: 6\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "snn = from_model(model=model, input_shape=(2, 34, 34), batch_size=1, spike_fn=spikegen.SingleSpike).spiking_model.to('cpu')\n",
    "mods = list(snn.modules())[1:]\n",
    "\n",
    "mems = list()\n",
    "\n",
    "# data = torch.tensor(np.load(f\"tensors/datafile.npy\"))\n",
    "data = torch.tensor(np.load(f\"./6174.npy\")).to(dtype=torch.float, device='cpu')\n",
    "print(f'Data Shape: {data.shape}\\n')\n",
    "outs = torch.zeros((data.shape[0], 10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    end_of_data = False\n",
    "    count = 0\n",
    "    failed = False\n",
    "    while not failed:\n",
    "        if not os.path.isfile(f\"tensors/x{count}.npy\"):\n",
    "            end_of_data = True\n",
    "            break\n",
    "\n",
    "        mod = mods[count % len(mods)]\n",
    "        mod_name = get_module_name(mod)\n",
    "\n",
    "        if count % len(mods) == 0:\n",
    "            #print(f'\\n====== BEGIN ITERATION {count // len(mods)} ======')\n",
    "            batch = count // len(mods)\n",
    "            x = data[batch].unsqueeze(0)\n",
    "            #print(f'Input sum: {x.sum()}')\n",
    "\n",
    "        # if (mod_name == 'IAFSqueeze'):\n",
    "        #     mod.record_states = True\n",
    "\n",
    "        # Get the data\n",
    "        #print(f\"Doing {mod_name}\")\n",
    "        x_hat = torch.tensor(np.load(f\"tensors/x{count}.npy\"))\n",
    "        x_new = mod(x)\n",
    "\n",
    "        # Handle wrong x case\n",
    "        x_correct = torch.isclose(x_new, x_hat, atol=1e-5)\n",
    "        correctness = torch.unique(x_correct)\n",
    "        if len(correctness) != 1 and correctness[0] == True:\n",
    "            failed = True\n",
    "            print(f'Failed at {mod_name}[{count % len(mods)}]')\n",
    "            wrong_idx = torch.stack(torch.where(x_correct == False), dim=1)\n",
    "            print(f'Total wrong {wrong_idx.shape[0]}')\n",
    "            for i in range(3):\n",
    "                r = torch.randint(0, wrong_idx.shape[0], (1,))\n",
    "                row = tuple(*(wrong_idx[r].tolist()))\n",
    "                print(f'Example {row}: {x_new[row]:.5f} != {x_hat.unsqueeze(0)[row]:.5f}')\n",
    "\n",
    "\n",
    "        if mod_name == 'Conv2d' and failed:\n",
    "            wrong_idx = torch.stack(torch.where(x_correct == False), dim=1)\n",
    "            # Check if error is on padding\n",
    "            non_boundary = False\n",
    "            for k in range(wrong_idx.shape[0]):\n",
    "                row = wrong_idx[k]\n",
    "                zeros = row[2] == 0 or row[3] == 0\n",
    "                limits = row[2] == x_new.shape[-2]-1 or row[3] == x_new.shape[-1]-1\n",
    "                if not (zeros or limits):\n",
    "                    print(f'Found non-boundary error: {row}')\n",
    "                    non_boundary = True\n",
    "\n",
    "            if not non_boundary:\n",
    "                print(f'convolution: all errors reside on boundary. Consider checking padding implementation.')\n",
    "            \n",
    "        \n",
    "        # if mod_name == 'IAFSqueeze':\n",
    "        #     recordings = mod.recordings['v_mem']\n",
    "        #     recordings_hat = torch.tensor(np.load(f\"tensors/membrane{count}.npy\")).reshape(recordings.shape)\n",
    "\n",
    "        #     mem_correct = torch.isclose(recordings_hat, recordings, atol=1e-5)\n",
    "        #     # print(f'IAF[{count % len(mods)}] Unique non-zero recordings: {len(torch.unique(recordings))-1}')\n",
    "        #     # print(f'IAF[{count % len(mods)}] Firings: {int(x_new.sum())}')\n",
    "        #     if len(torch.unique(mem_correct)) != 1 and torch.unique(mem_correct)[0] == True:\n",
    "        #         failed = True\n",
    "        #         print(f'Failed at {mod_name} - Membrane mismatch')\n",
    "        #         wrong_idx = torch.where(mem_correct == False)\n",
    "        #         wrong_i = 1\n",
    "        #         ex_pos = (int(wrong_idx[0][wrong_i]), int(wrong_idx[1][wrong_i]),\n",
    "        #                   int(wrong_idx[2][wrong_i]), int(wrong_idx[3][wrong_i]),\n",
    "        #                   int(wrong_idx[4][wrong_i]))\n",
    "        #         print(f'Example: {ex_pos}: {recordings[ex_pos]} != {recordings_hat[ex_pos[2:]]}')\n",
    "\n",
    "            \n",
    "        if (count+1) % len(mods) == 0:\n",
    "            outs[batch] = x_new[0]\n",
    "        x = x_new\n",
    "        count += 1\n",
    "    if failed:\n",
    "        print(f'\\nStopped: count {count}')\n",
    "    else:\n",
    "        print(f'\\nTest completed successfully.')\n",
    "        prediction = outs.sum(dim=0).argmax(dim=0, keepdim=True)\n",
    "        print(f'Prediction: {prediction.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e924c8-e61f-4de8-9d01-8b9715b70a42",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datai = 6174\n",
    "for i, (realdata, label) in enumerate(snn_test_dataloader):\n",
    "    if i == datai:\n",
    "        realdata = realdata.squeeze(0)\n",
    "        np.save(f\"./tensors/torch-datafile.npy\", realdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "3a092410-35d3-411a-b386-5fc8cb9757ee",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: torch.Size([100, 2, 34, 34])\n",
      "\n",
      "Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([100, 8, 34, 34])\n",
      "IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=1, num_timesteps=-1)\n",
      "torch.Size([100, 8, 34, 34])\n",
      "AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "torch.Size([100, 8, 17, 17])\n",
      "Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([100, 16, 17, 17])\n",
      "IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=1, num_timesteps=-1)\n",
      "torch.Size([100, 16, 17, 17])\n",
      "AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "torch.Size([100, 16, 8, 8])\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "torch.Size([100, 16, 4, 4])\n",
      "IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=1, num_timesteps=-1)\n",
      "torch.Size([100, 16, 4, 4])\n",
      "Flatten(start_dim=1, end_dim=-1)\n",
      "torch.Size([100, 256])\n",
      "Linear(in_features=256, out_features=10, bias=False)\n",
      "torch.Size([100, 10])\n",
      "IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=1, num_timesteps=-1)\n",
      "torch.Size([100, 10])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lol' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[714], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mlol\u001b[49m()\n\u001b[1;32m     20\u001b[0m prediction \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lol' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "# Grab the data\n",
    "#data = torch.tensor(np.load(f\"tensors/{datai}.npy\"))\n",
    "data = torch.tensor(np.load(f\"./{datai}.npy\")).to(dtype=torch.float, device='cpu')\n",
    "print(f'Data Shape: {data.shape}\\n')\n",
    "\n",
    "# Run through real network\n",
    "snn = from_model(model=model, input_shape=(2, 34, 34), batch_size=1, spike_fn=spikegen.SingleSpike).spiking_model.to('cpu')\n",
    "snn.eval()\n",
    "with torch.no_grad():\n",
    "    mods = list(snn.modules())[1:]\n",
    "    output = data\n",
    "    for m in mods:\n",
    "        output = m(output)\n",
    "        print(m)\n",
    "        print(output.shape)\n",
    "    lol()\n",
    "    prediction = output.sum(dim=0).argmax(dim=0, keepdim=True)\n",
    "    print(f'Prediction: {prediction.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "b9d98704-9d4b-4c4e-b4a3-20d38f53feda",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2, 34, 34]) torch.Size([100, 2, 34, 34])\n",
      "label: 6\n",
      "Total wrong 6591\n",
      "Example (47, 1, 27, 18): 1.00000 != 0.00000\n",
      "Example (95, 1, 8, 13): 0.00000 != 1.00000\n",
      "Example (85, 1, 10, 17): 1.00000 != 0.00000\n"
     ]
    }
   ],
   "source": [
    "for i, (realdata, label) in enumerate(snn_test_dataloader):\n",
    "    if i == datai:\n",
    "        realdata = realdata.squeeze(0)\n",
    "        np.save(f\"./{i}.npy\", realdata)\n",
    "        print(realdata.shape, data.shape)\n",
    "        print(f\"label: {label.item()}\")\n",
    "\n",
    "        wrong_idx = torch.stack(torch.where(realdata != data), dim=1)\n",
    "        print(f'Total wrong {wrong_idx.shape[0]}')\n",
    "        torch.manual_seed(0)\n",
    "        if wrong_idx.shape[0] > 0:\n",
    "            for i in range(3):\n",
    "                r = torch.randint(0, wrong_idx.shape[0], (1,))\n",
    "                row = tuple(*(wrong_idx[r].tolist()))\n",
    "                print(f'Example {row}: {data[row]:.5f} != {realdata[row]:.5f}')\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "1e9ac614-50bc-4866-82d9-60732e5a14e3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reset the snn for testing\n",
    "for m in mods:\n",
    "    mod_name = get_module_name(m)\n",
    "    if mod_name == \"IAFSqueeze\":\n",
    "        m.reset_states()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "d3e97817-56f9-46dc-af52-064aed68d3e9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Testing model.:   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Testing model.:   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([11.,  0.,  3.,  4.,  2.,  5.,  3.,  0.,  1.,  7.])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lol' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[708], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m correct_predictions\u001b[38;5;241m.\u001b[39mappend(pred\u001b[38;5;241m.\u001b[39meq(label\u001b[38;5;241m.\u001b[39mview_as(pred)))\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# set progressing bar\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mlol\u001b[49m()\n\u001b[1;32m     31\u001b[0m test_p_bar\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#test_p_bar.set_description(f\"Testing SNN Model...\")\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lol' is not defined"
     ]
    }
   ],
   "source": [
    "n_time_steps = 100\n",
    "to_raster = ToFrame(sensor_size=NMNIST.sensor_size, n_time_bins=n_time_steps)\n",
    "snn_test_dataset = NMNIST(save_to=root_dir, train=False, transform=to_raster)\n",
    "snn_test_dataloader = DataLoader(snn_test_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=False)\n",
    "#snn = from_model(model=model, input_shape=(2, 34, 34), batch_size=1, spike_fn=spikegen.SingleSpike).spiking_model.to('cpu')\n",
    "\n",
    "correct_predictions = []\n",
    "with torch.no_grad():\n",
    "    test_p_bar = tqdm(snn_test_dataloader,  desc=f'Testing model.', mininterval=1)\n",
    "    for data, label in test_p_bar:\n",
    "\n",
    "        # reshape the input from [Batch, Time, Channel, Height, Width] into [Batch*Time, Channel, Height, Width]\n",
    "        data = data.reshape(-1, 2, 34, 34).to(dtype=torch.float, device='cpu')\n",
    "        # forward\n",
    "        modules = list(snn.modules())[1:]\n",
    "        output = data\n",
    "        for m in modules:\n",
    "            output = m(output)\n",
    "        # reshape the output from [Batch*Time,num_classes] into [Batch, Time, num_classes]\n",
    "        output = output.reshape(batch_size, n_time_steps, -1)\n",
    "        print(output[0,0])\n",
    "        # accumulate all time-steps output for final prediction\n",
    "        output = output.sum(dim=1)\n",
    "        print(output[0])\n",
    "        # calculate accuracy\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        # compute the total correct predictions\n",
    "        correct_predictions.append(pred.eq(label.view_as(pred)))\n",
    "        # set progressing bar\n",
    "        lol()\n",
    "        test_p_bar.update()\n",
    "        #test_p_bar.set_description(f\"Testing SNN Model...\")\n",
    "\n",
    "    correct_predictions = torch.cat(correct_predictions)\n",
    "    print(f\"\\nAccuracy of converted SNN: {correct_predictions.sum().item()/(len(correct_predictions))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "f786645f-7a72-40ff-ba6e-26f4ee46f3c6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snn = from_model(model=model, input_shape=(2, 34, 34), batch_size=1, spike_fn=spikegen.SingleSpike).spiking_model.to('cpu')\n",
    "modules = list(snn.modules())[1:]\n",
    "iaf = modules[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e9d250-ffbd-48f4-a35b-718f80315b1a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iaf = sinabs.layers.IAFSqueeze(spike_fn=spikegen.SingleSpike, min_v_mem=-1, batch_size=1, record_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "141dceb7-1444-43cf-8492-ef66c5b2ad52",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape = [100, 8, 34, 34]\n",
    "rec = (5,0,24)\n",
    "data = torch.ones(shape) * 0.2\n",
    "\n",
    "my_if = if1_layer(shape, rec)\n",
    "\n",
    "out = iaf(data.clone())\n",
    "out_hat = my_if(data.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "ddb30fe4-ac7c-415b-8795-b0188a6c8cdd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total wrong 0\n"
     ]
    }
   ],
   "source": [
    "wrong_idx = torch.stack(torch.where(out_hat != out), dim=1)\n",
    "print(f'Total wrong {wrong_idx.shape[0]}')\n",
    "torch.manual_seed(0)\n",
    "if wrong_idx.shape[0] > 0:\n",
    "    for i in range(3):\n",
    "        r = torch.randint(0, wrong_idx.shape[0], (1,))\n",
    "        row = tuple(*(wrong_idx[r].tolist()))\n",
    "        print(f'Example {row}: {out[row]:.5f} != {out_hat[row]:.5f}')\n",
    "\n",
    "    c = 3\n",
    "    x = 0\n",
    "    y = 24\n",
    "    for i in range(shape[0]):\n",
    "        s = (i, c, x,y)\n",
    "        print(f\"{s}: {out[s]:5} ({iaf.recordings['v_mem'][(0,i) + rec]:5.5f}) | {out_hat[s]:5} ({my_if.recs[i]:5.5f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "id": "89485c25-8e4c-4902-8936-be34f718d0d9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f: tensor([True])\n",
      "pred: 2\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(np.load(\"./tensors/data.npy\"))\n",
    "snn = from_model(model=model, input_shape=(2, 34, 34), batch_size=1, spike_fn=spikegen.SingleSpike).spiking_model.to('cpu')\n",
    "modules = list(snn.modules())[1:]\n",
    "c0 = modules[0]\n",
    "i1 = modules[1]\n",
    "a2 = modules[2]\n",
    "c3 = modules[3]\n",
    "i4 = modules[4]\n",
    "a5 = modules[5]\n",
    "c6 = modules[6]\n",
    "i7 = modules[7]\n",
    "f8 = modules[8]\n",
    "l9 = modules[9]\n",
    "i10 = modules[10]\n",
    "\n",
    "x1 = c0(data)\n",
    "x1 = i1(x1)\n",
    "x1 = a2(x1)\n",
    "x1 = c3(x1)\n",
    "x1 = i4(x1)\n",
    "x1 = a5(x1)\n",
    "x1 = c6(x1)\n",
    "x1 = i7(x1)\n",
    "x1 = f8(x1)\n",
    "x1 = l9(x1)\n",
    "x1 = i10(x1)\n",
    "x2 = torch.tensor(np.load(\"./tensors/out.npy\"))\n",
    "blah = False\n",
    "if blah:\n",
    "    print(f\"e: {torch.unique(x1 == x2)}\")\n",
    "else:\n",
    "    print(f\"f: {torch.unique(torch.isclose(x1, x2, atol=1e-5))}\")\n",
    "\n",
    "x1 = x1.sum(dim=0)\n",
    "x1 = x1.argmax()\n",
    "print(f\"pred: {x1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "38242ec6-997d-4814-bb77-c51803ecec76",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total wrong 10185\n",
      "Example (81, 2, 3, 2): 0.08786 != 0.00000\n",
      "Example (10, 14, 1, 2): 0.22917 != 0.00000\n",
      "Example (25, 10, 3, 3): -0.01374 != 0.00000\n"
     ]
    }
   ],
   "source": [
    "wrong_idx = torch.stack(torch.where(x1 != x2), dim=1)\n",
    "print(f'Total wrong {wrong_idx.shape[0]}')\n",
    "#torch.manual_seed(0)\n",
    "if wrong_idx.shape[0] > 0:\n",
    "    for i in range(3):\n",
    "        r = torch.randint(0, wrong_idx.shape[0], (1,))\n",
    "        row = tuple(*(wrong_idx[r].tolist()))\n",
    "        print(f'Example {row}: {x1[row]:.5f} != {x2[row]:.5f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "id": "64e9b2a7-828a-4796-b55c-9964452dbc50",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = x1.sum(dim=0)\n",
    "x1.argmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "82139bd2-9579-4ec2-aa31-aa1f290daca9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2500)\n"
     ]
    }
   ],
   "source": [
    "def getIndex(source, dims):\n",
    "    v_index = dims[0]\n",
    "    for i in range(1, len(source)):\n",
    "        v_index = v_index * source[i] + dims[i]\n",
    "    return v_index\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "name": "snn-training.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
